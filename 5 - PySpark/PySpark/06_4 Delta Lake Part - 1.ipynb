{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5f4e96d2-eaa4-4336-b6ef-8a8195336895",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Delta Lake\n",
    "- **Understand SPARK Session**\n",
    "- **Check for Catalog Implementation [Hive]**\n",
    "- **List the databases in a catalog**\n",
    "- **List the tables in a databases within a catalog**\n",
    "- **Understand DBFS**\n",
    "- **Upload files to DBFS**\n",
    "- **Browse DBFS using UI and using DBUTILS**\n",
    "- **Create Parquet format table using PySpark**\n",
    "- **Create Delta table using PySpark**\n",
    "- **Understand the difference between Parquet and Delta Table**\n",
    "- **How Delta Table manages Metadata? What is Delta Log?**\n",
    "- **How Versioning works in Delta Lake?**\n",
    "- **DML Operations in Delta Table**\n",
    "- **Time Travel in Delta Lake**\n",
    "- **Schema Evolution in Delta Lake**\n",
    "- **Convert Parquet to Delta Table**\n",
    "- **Restoring to a version in Delta Lake**\n",
    "- **Vacuum operations in Delta Lake**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4da6755-5106-480f-bd2c-90a00c692252",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"/?o=2549120867740650#setting/sparkui/1223-070356-nnvl4fpv/driver-2728240433941798940\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[8]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7ffab61e9150>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SPARK Session\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df61b55c-a556-43b4-b1fd-30db2652cfcd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'hive'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for SPARK SQL Catalog Implementation - In-Memory, Hive, Unity Catalog\n",
    "spark.conf.get(\"spark.sql.catalogImplementation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8908ee52-c1ff-4edc-88af-d70bf83d2385",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>databaseName</th></tr></thead><tbody><tr><td>default</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "default"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 5
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "databaseName",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%sql\n",
    "show databases;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cfc9698-6329-4ea3-8a4e-762a48e231c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": null
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "create database qbex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8dccf7cd-4a6f-45f5-a801-bd1d63489ef1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>database</th><th>tableName</th><th>isTemporary</th></tr></thead><tbody><tr><td></td><td>_sqldf</td><td>true</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "",
         "_sqldf",
         true
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 6
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "database",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "tableName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "isTemporary",
         "type": "\"boolean\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%sql\n",
    "show tables in qbex;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "781b01e7-ecca-4f1e-93f1-58b6e4ee3a2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Employee Data and Schema\n",
    "emp_data = [\n",
    "    [\"E1\",\"Pratap\",\"Hyderabad\",1000],\n",
    "    [\"E2\",\"Sruthi\",\"Anantapur\",2000],\n",
    "    [\"E3\",\"Kiyanshitha\",\"Vizag\",3000]\n",
    "]\n",
    "\n",
    "emp_schema = \"empno string, empname string, city string, salary integer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46ee0dc8-7eb9-4e1f-9155-9998cb20f547",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>empno</th><th>empname</th><th>city</th><th>salary</th></tr></thead><tbody><tr><td>E1</td><td>Pratap</td><td>Hyderabad</td><td>1000</td></tr><tr><td>E2</td><td>Sruthi</td><td>Anantapur</td><td>2000</td></tr><tr><td>E3</td><td>Kiyanshitha</td><td>Vizag</td><td>3000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "E1",
         "Pratap",
         "Hyderabad",
         1000
        ],
        [
         "E2",
         "Sruthi",
         "Anantapur",
         2000
        ],
        [
         "E3",
         "Kiyanshitha",
         "Vizag",
         3000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "empno",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "empname",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "city",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create DataFrame from Data and Schema\n",
    "emp_df = spark.createDataFrame(data=emp_data, schema=emp_schema)\n",
    "display(emp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "956e50bc-f782-4b71-8129-00a787a363de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'empno,empname,city,salary\\r\\nE1,Pratap,Hyderabad,1000\\r\\nE2,Sruthi,Anantapur,2000\\r\\nE3,Kiyanshitha,Vizag,3000\\r\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display(dbutils.fs.ls(\"/FileStore/data/\"))\n",
    "\n",
    "dbutils.fs.head(\"/FileStore/data/emp_file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b50c353-c834-4b7a-8352-4319a72831ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>empno</th><th>empname</th><th>city</th><th>salary</th></tr></thead><tbody><tr><td>E1</td><td>Pratap</td><td>Hyderabad</td><td>1000</td></tr><tr><td>E2</td><td>Sruthi</td><td>Anantapur</td><td>2000</td></tr><tr><td>E3</td><td>Kiyanshitha</td><td>Vizag</td><td>3000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "E1",
         "Pratap",
         "Hyderabad",
         1000
        ],
        [
         "E2",
         "Sruthi",
         "Anantapur",
         2000
        ],
        [
         "E3",
         "Kiyanshitha",
         "Vizag",
         3000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "empno",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "empname",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "city",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "emp_fs_df = spark.read.format(\"csv\") \\\n",
    "                       .option(\"header\", True) \\\n",
    "                       .option(\"inferSchema\", True) \\\n",
    "                       .load(\"/FileStore/data/emp_file.csv\")    \n",
    "display(emp_fs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "914951d4-5048-4939-988b-12ec5164a4eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Understand DBFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a3386fd7-b0c7-4c6b-b303-894ba9aba75f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Upload Files to DBFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b9c822e3-59c8-4da7-b392-681d9eb50bd2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Browse Files in DBFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49b0455d-ce4f-417b-8696-b64f7f7285bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create Parquet format table using PySpark\n",
    "emp_fs_df.write.format(\"parquet\").mode(\"overwrite\").option(\"path\",\"/FileStore/data/sales_parquet_2\").saveAsTable(\"sales_parquet_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6edafbbc-e46c-4a03-895a-cd4cd1539dcb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>col_name</th><th>data_type</th><th>comment</th></tr></thead><tbody><tr><td>empno</td><td>string</td><td>null</td></tr><tr><td>empname</td><td>string</td><td>null</td></tr><tr><td>city</td><td>string</td><td>null</td></tr><tr><td>salary</td><td>int</td><td>null</td></tr><tr><td></td><td></td><td></td></tr><tr><td># Detailed Table Information</td><td></td><td></td></tr><tr><td>Catalog</td><td>spark_catalog</td><td></td></tr><tr><td>Database</td><td>default</td><td></td></tr><tr><td>Table</td><td>sales_parquet_2</td><td></td></tr><tr><td>Owner</td><td>root</td><td></td></tr><tr><td>Created Time</td><td>Mon Dec 23 09:18:30 UTC 2024</td><td></td></tr><tr><td>Last Access</td><td>UNKNOWN</td><td></td></tr><tr><td>Created By</td><td>Spark 3.5.0</td><td></td></tr><tr><td>Type</td><td>EXTERNAL</td><td></td></tr><tr><td>Provider</td><td>parquet</td><td></td></tr><tr><td>Location</td><td>dbfs:/FileStore/data/sales_parquet_2</td><td></td></tr><tr><td>Serde Library</td><td>org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe</td><td></td></tr><tr><td>InputFormat</td><td>org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat</td><td></td></tr><tr><td>OutputFormat</td><td>org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat</td><td></td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "empno",
         "string",
         null
        ],
        [
         "empname",
         "string",
         null
        ],
        [
         "city",
         "string",
         null
        ],
        [
         "salary",
         "int",
         null
        ],
        [
         "",
         "",
         ""
        ],
        [
         "# Detailed Table Information",
         "",
         ""
        ],
        [
         "Catalog",
         "spark_catalog",
         ""
        ],
        [
         "Database",
         "default",
         ""
        ],
        [
         "Table",
         "sales_parquet_2",
         ""
        ],
        [
         "Owner",
         "root",
         ""
        ],
        [
         "Created Time",
         "Mon Dec 23 09:18:30 UTC 2024",
         ""
        ],
        [
         "Last Access",
         "UNKNOWN",
         ""
        ],
        [
         "Created By",
         "Spark 3.5.0",
         ""
        ],
        [
         "Type",
         "EXTERNAL",
         ""
        ],
        [
         "Provider",
         "parquet",
         ""
        ],
        [
         "Location",
         "dbfs:/FileStore/data/sales_parquet_2",
         ""
        ],
        [
         "Serde Library",
         "org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe",
         ""
        ],
        [
         "InputFormat",
         "org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat",
         ""
        ],
        [
         "OutputFormat",
         "org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat",
         ""
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 19
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{\"comment\":\"name of the column\"}",
         "name": "col_name",
         "type": "\"string\""
        },
        {
         "metadata": "{\"comment\":\"data type of the column\"}",
         "name": "data_type",
         "type": "\"string\""
        },
        {
         "metadata": "{\"comment\":\"comment of the column\"}",
         "name": "comment",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%sql\n",
    "describe extended sales_parquet_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9660a969-29fd-499f-a4f9-5e0d80cadb0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>empno</th><th>empname</th><th>city</th><th>salary</th></tr></thead><tbody><tr><td>E1</td><td>Pratap</td><td>Hyderabad</td><td>1000</td></tr><tr><td>E2</td><td>Sruthi</td><td>Anantapur</td><td>2000</td></tr><tr><td>E3</td><td>Kiyanshitha</td><td>Vizag</td><td>3000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "E1",
         "Pratap",
         "Hyderabad",
         1000
        ],
        [
         "E2",
         "Sruthi",
         "Anantapur",
         2000
        ],
        [
         "E3",
         "Kiyanshitha",
         "Vizag",
         3000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 20
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "empno",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "empname",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "city",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select * from sales_parquet_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b44d9a07-9709-48f7-b0f6-ae8d8cff8770",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/FileStore/data/sales_parquet_2/_SUCCESS</td><td>_SUCCESS</td><td>0</td><td>1734945510000</td></tr><tr><td>dbfs:/FileStore/data/sales_parquet_2/_committed_822393280317452396</td><td>_committed_822393280317452396</td><td>122</td><td>1734945510000</td></tr><tr><td>dbfs:/FileStore/data/sales_parquet_2/_started_822393280317452396</td><td>_started_822393280317452396</td><td>0</td><td>1734945507000</td></tr><tr><td>dbfs:/FileStore/data/sales_parquet_2/part-00000-tid-822393280317452396-c3b667af-027e-496e-bdca-42f60f791629-25-1-c000.snappy.parquet</td><td>part-00000-tid-822393280317452396-c3b667af-027e-496e-bdca-42f60f791629-25-1-c000.snappy.parquet</td><td>1255</td><td>1734945510000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/FileStore/data/sales_parquet_2/_SUCCESS",
         "_SUCCESS",
         0,
         1734945510000
        ],
        [
         "dbfs:/FileStore/data/sales_parquet_2/_committed_822393280317452396",
         "_committed_822393280317452396",
         122,
         1734945510000
        ],
        [
         "dbfs:/FileStore/data/sales_parquet_2/_started_822393280317452396",
         "_started_822393280317452396",
         0,
         1734945507000
        ],
        [
         "dbfs:/FileStore/data/sales_parquet_2/part-00000-tid-822393280317452396-c3b667af-027e-496e-bdca-42f60f791629-25-1-c000.snappy.parquet",
         "part-00000-tid-822393280317452396-c3b667af-027e-496e-bdca-42f60f791629-25-1-c000.snappy.parquet",
         1255,
         1734945510000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Understand the File Structure of Parquet Table\n",
    "display(dbutils.fs.ls(\"/FileStore/data/sales_parquet_2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "394237f4-159d-4613-a55e-a5b5e8de3205",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create Delta format table using PySpark\n",
    "emp_fs_df.write.format(\"delta\").mode(\"overwrite\").option(\"path\", \"/FileStore/data/sales_delta_2\").saveAsTable(\"sales_delta_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa2a1863-8322-430d-b3f0-99695cff6a6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>col_name</th><th>data_type</th><th>comment</th></tr></thead><tbody><tr><td>empno</td><td>string</td><td>null</td></tr><tr><td>empname</td><td>string</td><td>null</td></tr><tr><td>city</td><td>string</td><td>null</td></tr><tr><td>salary</td><td>int</td><td>null</td></tr><tr><td></td><td></td><td></td></tr><tr><td># Delta Statistics Columns</td><td></td><td></td></tr><tr><td>Column Names</td><td>empno, empname, city, salary</td><td></td></tr><tr><td>Column Selection Method</td><td>first-32</td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td># Detailed Table Information</td><td></td><td></td></tr><tr><td>Catalog</td><td>spark_catalog</td><td></td></tr><tr><td>Database</td><td>default</td><td></td></tr><tr><td>Table</td><td>sales_delta_2</td><td></td></tr><tr><td>Created Time</td><td>Mon Dec 23 09:21:43 UTC 2024</td><td></td></tr><tr><td>Last Access</td><td>UNKNOWN</td><td></td></tr><tr><td>Created By</td><td>Spark 3.5.0</td><td></td></tr><tr><td>Type</td><td>EXTERNAL</td><td></td></tr><tr><td>Location</td><td>dbfs:/FileStore/data/sales_delta_2</td><td></td></tr><tr><td>Provider</td><td>delta</td><td></td></tr><tr><td>Owner</td><td>root</td><td></td></tr><tr><td>Table Properties</td><td>[delta.minReaderVersion=1,delta.minWriterVersion=2]</td><td></td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "empno",
         "string",
         null
        ],
        [
         "empname",
         "string",
         null
        ],
        [
         "city",
         "string",
         null
        ],
        [
         "salary",
         "int",
         null
        ],
        [
         "",
         "",
         ""
        ],
        [
         "# Delta Statistics Columns",
         "",
         ""
        ],
        [
         "Column Names",
         "empno, empname, city, salary",
         ""
        ],
        [
         "Column Selection Method",
         "first-32",
         ""
        ],
        [
         "",
         "",
         ""
        ],
        [
         "# Detailed Table Information",
         "",
         ""
        ],
        [
         "Catalog",
         "spark_catalog",
         ""
        ],
        [
         "Database",
         "default",
         ""
        ],
        [
         "Table",
         "sales_delta_2",
         ""
        ],
        [
         "Created Time",
         "Mon Dec 23 09:21:43 UTC 2024",
         ""
        ],
        [
         "Last Access",
         "UNKNOWN",
         ""
        ],
        [
         "Created By",
         "Spark 3.5.0",
         ""
        ],
        [
         "Type",
         "EXTERNAL",
         ""
        ],
        [
         "Location",
         "dbfs:/FileStore/data/sales_delta_2",
         ""
        ],
        [
         "Provider",
         "delta",
         ""
        ],
        [
         "Owner",
         "root",
         ""
        ],
        [
         "Table Properties",
         "[delta.minReaderVersion=1,delta.minWriterVersion=2]",
         ""
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 25
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{\"comment\":\"name of the column\"}",
         "name": "col_name",
         "type": "\"string\""
        },
        {
         "metadata": "{\"comment\":\"data type of the column\"}",
         "name": "data_type",
         "type": "\"string\""
        },
        {
         "metadata": "{\"comment\":\"comment of the column\"}",
         "name": "comment",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%sql\n",
    "describe extended sales_delta_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c3ce7bc-f041-4cbb-9956-1e0503d0ecd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>empno</th><th>empname</th><th>city</th><th>salary</th></tr></thead><tbody><tr><td>E1</td><td>Pratap</td><td>Hyderabad</td><td>1000</td></tr><tr><td>E2</td><td>Sruthi</td><td>Anantapur</td><td>2000</td></tr><tr><td>E3</td><td>Kiyanshitha</td><td>Vizag</td><td>3000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "E1",
         "Pratap",
         "Hyderabad",
         1000
        ],
        [
         "E2",
         "Sruthi",
         "Anantapur",
         2000
        ],
        [
         "E3",
         "Kiyanshitha",
         "Vizag",
         3000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 26
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "empno",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "empname",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "city",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select * from sales_delta_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5adb85b-f6f8-48cd-b705-19850fd1c5a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/FileStore/data/sales_delta_2/_delta_log/00000000000000000000.crc</td><td>00000000000000000000.crc</td><td>2743</td><td>1734945703000</td></tr><tr><td>dbfs:/FileStore/data/sales_delta_2/_delta_log/00000000000000000000.json</td><td>00000000000000000000.json</td><td>1869</td><td>1734945694000</td></tr><tr><td>dbfs:/FileStore/data/sales_delta_2/_delta_log/_commits/</td><td>_commits/</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/FileStore/data/sales_delta_2/_delta_log/00000000000000000000.crc",
         "00000000000000000000.crc",
         2743,
         1734945703000
        ],
        [
         "dbfs:/FileStore/data/sales_delta_2/_delta_log/00000000000000000000.json",
         "00000000000000000000.json",
         1869,
         1734945694000
        ],
        [
         "dbfs:/FileStore/data/sales_delta_2/_delta_log/_commits/",
         "_commits/",
         0,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Understand the File Structure of Delta Table & also Delta Log\n",
    "display(dbutils.fs.ls(\"/FileStore/data/sales_delta_2/_delta_log/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09480e55-0071-4d1c-b584-b69741abde4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>version</th><th>timestamp</th><th>userId</th><th>userName</th><th>operation</th><th>operationParameters</th><th>job</th><th>notebook</th><th>clusterId</th><th>readVersion</th><th>isolationLevel</th><th>isBlindAppend</th><th>operationMetrics</th><th>userMetadata</th><th>engineInfo</th></tr></thead><tbody><tr><td>0</td><td>2024-12-23T09:21:34Z</td><td>141785285425900</td><td>qbex.azure@gmail.com</td><td>CREATE OR REPLACE TABLE AS SELECT</td><td>Map(partitionBy -> [], clusterBy -> [], description -> null, isManaged -> false, properties -> {}, statsOnLoad -> false)</td><td>null</td><td>List(4005581910905466)</td><td>1223-070356-nnvl4fpv</td><td>null</td><td>WriteSerializable</td><td>false</td><td>Map(numFiles -> 1, numOutputRows -> 3, numOutputBytes -> 1255)</td><td>null</td><td>Databricks-Runtime/15.4.x-scala2.12</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         0,
         "2024-12-23T09:21:34Z",
         "141785285425900",
         "qbex.azure@gmail.com",
         "CREATE OR REPLACE TABLE AS SELECT",
         {
          "clusterBy": "[]",
          "description": null,
          "isManaged": "false",
          "partitionBy": "[]",
          "properties": "{}",
          "statsOnLoad": "false"
         },
         null,
         [
          "4005581910905466"
         ],
         "1223-070356-nnvl4fpv",
         null,
         "WriteSerializable",
         false,
         {
          "numFiles": "1",
          "numOutputBytes": "1255",
          "numOutputRows": "3"
         },
         null,
         "Databricks-Runtime/15.4.x-scala2.12"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 29
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "version",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "timestamp",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "userId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "userName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operation",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operationParameters",
         "type": "{\"type\":\"map\",\"keyType\":\"string\",\"valueType\":\"string\",\"valueContainsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "job",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"jobId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"jobName\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"jobRunId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"runId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"jobOwnerId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"triggerType\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "notebook",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"notebookId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "clusterId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "readVersion",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "isolationLevel",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "isBlindAppend",
         "type": "\"boolean\""
        },
        {
         "metadata": "{}",
         "name": "operationMetrics",
         "type": "{\"type\":\"map\",\"keyType\":\"string\",\"valueType\":\"string\",\"valueContainsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "userMetadata",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "engineInfo",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "describe history sales_delta_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f08035d-e0c2-4f47-839f-1fc2649471c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>empno</th><th>empname</th><th>city</th><th>salary</th></tr></thead><tbody><tr><td>E1</td><td>Pratap</td><td>Hyderabad</td><td>1000</td></tr><tr><td>E2</td><td>Sruthi</td><td>Anantapur</td><td>2000</td></tr><tr><td>E3</td><td>Kiyanshitha</td><td>Vizag</td><td>3000</td></tr><tr><td>E4</td><td>nirupama</td><td>hyderabad</td><td>50000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "E1",
         "Pratap",
         "Hyderabad",
         1000
        ],
        [
         "E2",
         "Sruthi",
         "Anantapur",
         2000
        ],
        [
         "E3",
         "Kiyanshitha",
         "Vizag",
         3000
        ],
        [
         "E4",
         "nirupama",
         "hyderabad",
         50000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 33
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "empno",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "empname",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "city",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "-- select * from sales_delta_2;\n",
    "select * from sales_parquet_2;\n",
    "\n",
    "-- update sales_parquet_2 set salary = 9999 where empno = 'E1';\n",
    "-- DELETE from sales_parquet_2 where empno = 'E1';\n",
    "-- insert into sales_parquet_2 values ('E4','nirupama','hyderabad',50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16f41196-c53e-4fb9-8612-e6890d7e04ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>version</th><th>timestamp</th><th>userId</th><th>userName</th><th>operation</th><th>operationParameters</th><th>job</th><th>notebook</th><th>clusterId</th><th>readVersion</th><th>isolationLevel</th><th>isBlindAppend</th><th>operationMetrics</th><th>userMetadata</th><th>engineInfo</th></tr></thead><tbody><tr><td>4</td><td>2024-12-23T09:30:47Z</td><td>141785285425900</td><td>qbex.azure@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, statsOnLoad -> false, partitionBy -> [])</td><td>null</td><td>List(4005581910905466)</td><td>1223-070356-nnvl4fpv</td><td>3</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 1, numOutputBytes -> 1242)</td><td>null</td><td>Databricks-Runtime/15.4.x-scala2.12</td></tr><tr><td>3</td><td>2024-12-23T09:29:14Z</td><td>141785285425900</td><td>qbex.azure@gmail.com</td><td>UPDATE</td><td>Map(predicate -> [\"(empno#3836 = E1)\"])</td><td>null</td><td>List(4005581910905466)</td><td>1223-070356-nnvl4fpv</td><td>2</td><td>WriteSerializable</td><td>false</td><td>Map(numRemovedFiles -> 1, numRemovedBytes -> 1255, numCopiedRows -> 2, numDeletionVectorsAdded -> 0, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 1713, numDeletionVectorsUpdated -> 0, scanTimeMs -> 718, numAddedFiles -> 1, numUpdatedRows -> 1, numAddedBytes -> 1255, rewriteTimeMs -> 995)</td><td>null</td><td>Databricks-Runtime/15.4.x-scala2.12</td></tr><tr><td>2</td><td>2024-12-23T09:28:14Z</td><td>141785285425900</td><td>qbex.azure@gmail.com</td><td>UPDATE</td><td>Map(predicate -> [\"(empno#2854 = E1)\"])</td><td>null</td><td>List(4005581910905466)</td><td>1223-070356-nnvl4fpv</td><td>1</td><td>WriteSerializable</td><td>false</td><td>Map(numRemovedFiles -> 1, numRemovedBytes -> 1255, numCopiedRows -> 2, numDeletionVectorsAdded -> 0, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 2189, numDeletionVectorsUpdated -> 0, scanTimeMs -> 1357, numAddedFiles -> 1, numUpdatedRows -> 1, numAddedBytes -> 1255, rewriteTimeMs -> 832)</td><td>null</td><td>Databricks-Runtime/15.4.x-scala2.12</td></tr><tr><td>1</td><td>2024-12-23T09:28:02Z</td><td>141785285425900</td><td>qbex.azure@gmail.com</td><td>UPDATE</td><td>Map(predicate -> [\"(empno#2283 = E1)\"])</td><td>null</td><td>List(4005581910905466)</td><td>1223-070356-nnvl4fpv</td><td>0</td><td>WriteSerializable</td><td>false</td><td>Map(numRemovedFiles -> 1, numRemovedBytes -> 1255, numCopiedRows -> 2, numDeletionVectorsAdded -> 0, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 3129, numDeletionVectorsUpdated -> 0, scanTimeMs -> 1751, numAddedFiles -> 1, numUpdatedRows -> 1, numAddedBytes -> 1255, rewriteTimeMs -> 1364)</td><td>null</td><td>Databricks-Runtime/15.4.x-scala2.12</td></tr><tr><td>0</td><td>2024-12-23T09:21:34Z</td><td>141785285425900</td><td>qbex.azure@gmail.com</td><td>CREATE OR REPLACE TABLE AS SELECT</td><td>Map(partitionBy -> [], clusterBy -> [], description -> null, isManaged -> false, properties -> {}, statsOnLoad -> false)</td><td>null</td><td>List(4005581910905466)</td><td>1223-070356-nnvl4fpv</td><td>null</td><td>WriteSerializable</td><td>false</td><td>Map(numFiles -> 1, numOutputRows -> 3, numOutputBytes -> 1255)</td><td>null</td><td>Databricks-Runtime/15.4.x-scala2.12</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         4,
         "2024-12-23T09:30:47Z",
         "141785285425900",
         "qbex.azure@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]",
          "statsOnLoad": "false"
         },
         null,
         [
          "4005581910905466"
         ],
         "1223-070356-nnvl4fpv",
         3,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "1242",
          "numOutputRows": "1"
         },
         null,
         "Databricks-Runtime/15.4.x-scala2.12"
        ],
        [
         3,
         "2024-12-23T09:29:14Z",
         "141785285425900",
         "qbex.azure@gmail.com",
         "UPDATE",
         {
          "predicate": "[\"(empno#3836 = E1)\"]"
         },
         null,
         [
          "4005581910905466"
         ],
         "1223-070356-nnvl4fpv",
         2,
         "WriteSerializable",
         false,
         {
          "executionTimeMs": "1713",
          "numAddedBytes": "1255",
          "numAddedChangeFiles": "0",
          "numAddedFiles": "1",
          "numCopiedRows": "2",
          "numDeletionVectorsAdded": "0",
          "numDeletionVectorsRemoved": "0",
          "numDeletionVectorsUpdated": "0",
          "numRemovedBytes": "1255",
          "numRemovedFiles": "1",
          "numUpdatedRows": "1",
          "rewriteTimeMs": "995",
          "scanTimeMs": "718"
         },
         null,
         "Databricks-Runtime/15.4.x-scala2.12"
        ],
        [
         2,
         "2024-12-23T09:28:14Z",
         "141785285425900",
         "qbex.azure@gmail.com",
         "UPDATE",
         {
          "predicate": "[\"(empno#2854 = E1)\"]"
         },
         null,
         [
          "4005581910905466"
         ],
         "1223-070356-nnvl4fpv",
         1,
         "WriteSerializable",
         false,
         {
          "executionTimeMs": "2189",
          "numAddedBytes": "1255",
          "numAddedChangeFiles": "0",
          "numAddedFiles": "1",
          "numCopiedRows": "2",
          "numDeletionVectorsAdded": "0",
          "numDeletionVectorsRemoved": "0",
          "numDeletionVectorsUpdated": "0",
          "numRemovedBytes": "1255",
          "numRemovedFiles": "1",
          "numUpdatedRows": "1",
          "rewriteTimeMs": "832",
          "scanTimeMs": "1357"
         },
         null,
         "Databricks-Runtime/15.4.x-scala2.12"
        ],
        [
         1,
         "2024-12-23T09:28:02Z",
         "141785285425900",
         "qbex.azure@gmail.com",
         "UPDATE",
         {
          "predicate": "[\"(empno#2283 = E1)\"]"
         },
         null,
         [
          "4005581910905466"
         ],
         "1223-070356-nnvl4fpv",
         0,
         "WriteSerializable",
         false,
         {
          "executionTimeMs": "3129",
          "numAddedBytes": "1255",
          "numAddedChangeFiles": "0",
          "numAddedFiles": "1",
          "numCopiedRows": "2",
          "numDeletionVectorsAdded": "0",
          "numDeletionVectorsRemoved": "0",
          "numDeletionVectorsUpdated": "0",
          "numRemovedBytes": "1255",
          "numRemovedFiles": "1",
          "numUpdatedRows": "1",
          "rewriteTimeMs": "1364",
          "scanTimeMs": "1751"
         },
         null,
         "Databricks-Runtime/15.4.x-scala2.12"
        ],
        [
         0,
         "2024-12-23T09:21:34Z",
         "141785285425900",
         "qbex.azure@gmail.com",
         "CREATE OR REPLACE TABLE AS SELECT",
         {
          "clusterBy": "[]",
          "description": null,
          "isManaged": "false",
          "partitionBy": "[]",
          "properties": "{}",
          "statsOnLoad": "false"
         },
         null,
         [
          "4005581910905466"
         ],
         "1223-070356-nnvl4fpv",
         null,
         "WriteSerializable",
         false,
         {
          "numFiles": "1",
          "numOutputBytes": "1255",
          "numOutputRows": "3"
         },
         null,
         "Databricks-Runtime/15.4.x-scala2.12"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 49
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "version",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "timestamp",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "userId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "userName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operation",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operationParameters",
         "type": "{\"type\":\"map\",\"keyType\":\"string\",\"valueType\":\"string\",\"valueContainsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "job",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"jobId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"jobName\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"jobRunId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"runId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"jobOwnerId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"triggerType\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "notebook",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"notebookId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "clusterId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "readVersion",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "isolationLevel",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "isBlindAppend",
         "type": "\"boolean\""
        },
        {
         "metadata": "{}",
         "name": "operationMetrics",
         "type": "{\"type\":\"map\",\"keyType\":\"string\",\"valueType\":\"string\",\"valueContainsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "userMetadata",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "engineInfo",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "-- select * from sales_delta_2;\n",
    "describe history sales_delta_2;\n",
    "-- select * from sales_parquet_2;\n",
    "\n",
    "-- update sales_delta_2 set salary = 8888 where empno = 'E1';\n",
    "-- DELETE from sales_delta_2 where empno = 'E1';\n",
    "-- insert into sales_delta_2 values ('E4','nirupama','hyderabad',50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea3f9eb6-5d5b-4b21-a4b8-89e87ed915ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Query Delta table of different versions - Time Travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19ab940e-2a6b-4403-bfcd-f085247e78a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Schema Evolution - Change schema for one record\n",
    "# Employee Data and Schema\n",
    "emp_data = [\n",
    "    [\"E5\",\"Chand\",\"Hyderabad\",77777, \"India\"]\n",
    "]\n",
    "\n",
    "emp_schema = \"empno string, empname string, city string, salary integer, countr string\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09e420da-5b50-46f8-bf0c-a602bfd22873",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "emp_new_df = spark.createDataFrame(data=emp_data, schema=emp_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "faee32db-3525-4e60-9813-a765325046db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "emp_new_df.write.format(\"delta\").mode(\"append\").option(\"mergeSchema\",True).option(\"path\", \"/FileStore/data/sales_delta_2\").saveAsTable(\"sales_delta_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd02248c-a89a-4216-9b4e-41bb5f378029",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>empno</th><th>empname</th><th>city</th><th>salary</th><th>countr</th></tr></thead><tbody><tr><td>E5</td><td>Chand</td><td>Hyderabad</td><td>77777</td><td>India</td></tr><tr><td>E1</td><td>Pratap</td><td>Hyderabad</td><td>8888</td><td>null</td></tr><tr><td>E2</td><td>Sruthi</td><td>Anantapur</td><td>2000</td><td>null</td></tr><tr><td>E3</td><td>Kiyanshitha</td><td>Vizag</td><td>3000</td><td>null</td></tr><tr><td>E4</td><td>nirupama</td><td>hyderabad</td><td>50000</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "E5",
         "Chand",
         "Hyderabad",
         77777,
         "India"
        ],
        [
         "E1",
         "Pratap",
         "Hyderabad",
         8888,
         null
        ],
        [
         "E2",
         "Sruthi",
         "Anantapur",
         2000,
         null
        ],
        [
         "E3",
         "Kiyanshitha",
         "Vizag",
         3000,
         null
        ],
        [
         "E4",
         "nirupama",
         "hyderabad",
         50000,
         null
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 54
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "empno",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "empname",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "city",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "countr",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select * from sales_delta_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "116a40e1-67dd-4c91-8e9c-df22a3e9a734",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>version</th><th>timestamp</th><th>userId</th><th>userName</th><th>operation</th><th>operationParameters</th><th>job</th><th>notebook</th><th>clusterId</th><th>readVersion</th><th>isolationLevel</th><th>isBlindAppend</th><th>operationMetrics</th><th>userMetadata</th><th>engineInfo</th></tr></thead><tbody><tr><td>5</td><td>2024-12-23T09:47:25Z</td><td>141785285425900</td><td>qbex.azure@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, statsOnLoad -> false, partitionBy -> [])</td><td>null</td><td>List(4005581910905466)</td><td>1223-070356-nnvl4fpv</td><td>4</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 1, numOutputBytes -> 1466)</td><td>null</td><td>Databricks-Runtime/15.4.x-scala2.12</td></tr><tr><td>4</td><td>2024-12-23T09:30:47Z</td><td>141785285425900</td><td>qbex.azure@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, statsOnLoad -> false, partitionBy -> [])</td><td>null</td><td>List(4005581910905466)</td><td>1223-070356-nnvl4fpv</td><td>3</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 1, numOutputBytes -> 1242)</td><td>null</td><td>Databricks-Runtime/15.4.x-scala2.12</td></tr><tr><td>3</td><td>2024-12-23T09:29:14Z</td><td>141785285425900</td><td>qbex.azure@gmail.com</td><td>UPDATE</td><td>Map(predicate -> [\"(empno#3836 = E1)\"])</td><td>null</td><td>List(4005581910905466)</td><td>1223-070356-nnvl4fpv</td><td>2</td><td>WriteSerializable</td><td>false</td><td>Map(numRemovedFiles -> 1, numRemovedBytes -> 1255, numCopiedRows -> 2, numDeletionVectorsAdded -> 0, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 1713, numDeletionVectorsUpdated -> 0, scanTimeMs -> 718, numAddedFiles -> 1, numUpdatedRows -> 1, numAddedBytes -> 1255, rewriteTimeMs -> 995)</td><td>null</td><td>Databricks-Runtime/15.4.x-scala2.12</td></tr><tr><td>2</td><td>2024-12-23T09:28:14Z</td><td>141785285425900</td><td>qbex.azure@gmail.com</td><td>UPDATE</td><td>Map(predicate -> [\"(empno#2854 = E1)\"])</td><td>null</td><td>List(4005581910905466)</td><td>1223-070356-nnvl4fpv</td><td>1</td><td>WriteSerializable</td><td>false</td><td>Map(numRemovedFiles -> 1, numRemovedBytes -> 1255, numCopiedRows -> 2, numDeletionVectorsAdded -> 0, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 2189, numDeletionVectorsUpdated -> 0, scanTimeMs -> 1357, numAddedFiles -> 1, numUpdatedRows -> 1, numAddedBytes -> 1255, rewriteTimeMs -> 832)</td><td>null</td><td>Databricks-Runtime/15.4.x-scala2.12</td></tr><tr><td>1</td><td>2024-12-23T09:28:02Z</td><td>141785285425900</td><td>qbex.azure@gmail.com</td><td>UPDATE</td><td>Map(predicate -> [\"(empno#2283 = E1)\"])</td><td>null</td><td>List(4005581910905466)</td><td>1223-070356-nnvl4fpv</td><td>0</td><td>WriteSerializable</td><td>false</td><td>Map(numRemovedFiles -> 1, numRemovedBytes -> 1255, numCopiedRows -> 2, numDeletionVectorsAdded -> 0, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 3129, numDeletionVectorsUpdated -> 0, scanTimeMs -> 1751, numAddedFiles -> 1, numUpdatedRows -> 1, numAddedBytes -> 1255, rewriteTimeMs -> 1364)</td><td>null</td><td>Databricks-Runtime/15.4.x-scala2.12</td></tr><tr><td>0</td><td>2024-12-23T09:21:34Z</td><td>141785285425900</td><td>qbex.azure@gmail.com</td><td>CREATE OR REPLACE TABLE AS SELECT</td><td>Map(partitionBy -> [], clusterBy -> [], description -> null, isManaged -> false, properties -> {}, statsOnLoad -> false)</td><td>null</td><td>List(4005581910905466)</td><td>1223-070356-nnvl4fpv</td><td>null</td><td>WriteSerializable</td><td>false</td><td>Map(numFiles -> 1, numOutputRows -> 3, numOutputBytes -> 1255)</td><td>null</td><td>Databricks-Runtime/15.4.x-scala2.12</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         5,
         "2024-12-23T09:47:25Z",
         "141785285425900",
         "qbex.azure@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]",
          "statsOnLoad": "false"
         },
         null,
         [
          "4005581910905466"
         ],
         "1223-070356-nnvl4fpv",
         4,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "1466",
          "numOutputRows": "1"
         },
         null,
         "Databricks-Runtime/15.4.x-scala2.12"
        ],
        [
         4,
         "2024-12-23T09:30:47Z",
         "141785285425900",
         "qbex.azure@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]",
          "statsOnLoad": "false"
         },
         null,
         [
          "4005581910905466"
         ],
         "1223-070356-nnvl4fpv",
         3,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "1242",
          "numOutputRows": "1"
         },
         null,
         "Databricks-Runtime/15.4.x-scala2.12"
        ],
        [
         3,
         "2024-12-23T09:29:14Z",
         "141785285425900",
         "qbex.azure@gmail.com",
         "UPDATE",
         {
          "predicate": "[\"(empno#3836 = E1)\"]"
         },
         null,
         [
          "4005581910905466"
         ],
         "1223-070356-nnvl4fpv",
         2,
         "WriteSerializable",
         false,
         {
          "executionTimeMs": "1713",
          "numAddedBytes": "1255",
          "numAddedChangeFiles": "0",
          "numAddedFiles": "1",
          "numCopiedRows": "2",
          "numDeletionVectorsAdded": "0",
          "numDeletionVectorsRemoved": "0",
          "numDeletionVectorsUpdated": "0",
          "numRemovedBytes": "1255",
          "numRemovedFiles": "1",
          "numUpdatedRows": "1",
          "rewriteTimeMs": "995",
          "scanTimeMs": "718"
         },
         null,
         "Databricks-Runtime/15.4.x-scala2.12"
        ],
        [
         2,
         "2024-12-23T09:28:14Z",
         "141785285425900",
         "qbex.azure@gmail.com",
         "UPDATE",
         {
          "predicate": "[\"(empno#2854 = E1)\"]"
         },
         null,
         [
          "4005581910905466"
         ],
         "1223-070356-nnvl4fpv",
         1,
         "WriteSerializable",
         false,
         {
          "executionTimeMs": "2189",
          "numAddedBytes": "1255",
          "numAddedChangeFiles": "0",
          "numAddedFiles": "1",
          "numCopiedRows": "2",
          "numDeletionVectorsAdded": "0",
          "numDeletionVectorsRemoved": "0",
          "numDeletionVectorsUpdated": "0",
          "numRemovedBytes": "1255",
          "numRemovedFiles": "1",
          "numUpdatedRows": "1",
          "rewriteTimeMs": "832",
          "scanTimeMs": "1357"
         },
         null,
         "Databricks-Runtime/15.4.x-scala2.12"
        ],
        [
         1,
         "2024-12-23T09:28:02Z",
         "141785285425900",
         "qbex.azure@gmail.com",
         "UPDATE",
         {
          "predicate": "[\"(empno#2283 = E1)\"]"
         },
         null,
         [
          "4005581910905466"
         ],
         "1223-070356-nnvl4fpv",
         0,
         "WriteSerializable",
         false,
         {
          "executionTimeMs": "3129",
          "numAddedBytes": "1255",
          "numAddedChangeFiles": "0",
          "numAddedFiles": "1",
          "numCopiedRows": "2",
          "numDeletionVectorsAdded": "0",
          "numDeletionVectorsRemoved": "0",
          "numDeletionVectorsUpdated": "0",
          "numRemovedBytes": "1255",
          "numRemovedFiles": "1",
          "numUpdatedRows": "1",
          "rewriteTimeMs": "1364",
          "scanTimeMs": "1751"
         },
         null,
         "Databricks-Runtime/15.4.x-scala2.12"
        ],
        [
         0,
         "2024-12-23T09:21:34Z",
         "141785285425900",
         "qbex.azure@gmail.com",
         "CREATE OR REPLACE TABLE AS SELECT",
         {
          "clusterBy": "[]",
          "description": null,
          "isManaged": "false",
          "partitionBy": "[]",
          "properties": "{}",
          "statsOnLoad": "false"
         },
         null,
         [
          "4005581910905466"
         ],
         "1223-070356-nnvl4fpv",
         null,
         "WriteSerializable",
         false,
         {
          "numFiles": "1",
          "numOutputBytes": "1255",
          "numOutputRows": "3"
         },
         null,
         "Databricks-Runtime/15.4.x-scala2.12"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "version",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "timestamp",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "userId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "userName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operation",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operationParameters",
         "type": "{\"type\":\"map\",\"keyType\":\"string\",\"valueType\":\"string\",\"valueContainsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "job",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"jobId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"jobName\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"jobRunId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"runId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"jobOwnerId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"triggerType\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "notebook",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"notebookId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "clusterId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "readVersion",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "isolationLevel",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "isBlindAppend",
         "type": "\"boolean\""
        },
        {
         "metadata": "{}",
         "name": "operationMetrics",
         "type": "{\"type\":\"map\",\"keyType\":\"string\",\"valueType\":\"string\",\"valueContainsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "userMetadata",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "engineInfo",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DeltaTable Library\n",
    "from delta import DeltaTable\n",
    "dt = DeltaTable.forName(spark,\"sales_delta_2\")\n",
    "display(dt.history())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "972deddb-e57d-4638-bc9b-c75b2acab363",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert Parquet to Delta Table\n",
    "DeltaTable.isDeltaTable(spark,\"/FileStore/data/sales_parquet_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd85eee1-ce5e-4ed1-a922-0831acb502eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<delta.tables.DeltaTable at 0x7ffa7db53a50>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DeltaTable.convertToDelta(spark,\"parquet.`/FileStore/data/sales_parquet_2`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc1e26d1-5d01-451b-8d0b-6879cba8c8ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/FileStore/data/sales_parquet_2/_SUCCESS</td><td>_SUCCESS</td><td>0</td><td>1734946217000</td></tr><tr><td>dbfs:/FileStore/data/sales_parquet_2/_committed_4376580291416143822</td><td>_committed_4376580291416143822</td><td>124</td><td>1734946217000</td></tr><tr><td>dbfs:/FileStore/data/sales_parquet_2/_committed_6589554690584742466</td><td>_committed_6589554690584742466</td><td>123</td><td>1734946013000</td></tr><tr><td>dbfs:/FileStore/data/sales_parquet_2/_committed_822393280317452396</td><td>_committed_822393280317452396</td><td>122</td><td>1734945510000</td></tr><tr><td>dbfs:/FileStore/data/sales_parquet_2/_delta_log/</td><td>_delta_log/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/FileStore/data/sales_parquet_2/_started_4376580291416143822</td><td>_started_4376580291416143822</td><td>0</td><td>1734946216000</td></tr><tr><td>dbfs:/FileStore/data/sales_parquet_2/_started_6589554690584742466</td><td>_started_6589554690584742466</td><td>0</td><td>1734946012000</td></tr><tr><td>dbfs:/FileStore/data/sales_parquet_2/_started_822393280317452396</td><td>_started_822393280317452396</td><td>0</td><td>1734945507000</td></tr><tr><td>dbfs:/FileStore/data/sales_parquet_2/part-00000-tid-4376580291416143822-0a9fa6c7-7345-4370-9549-b8701811137e-193-1-c000.snappy.parquet</td><td>part-00000-tid-4376580291416143822-0a9fa6c7-7345-4370-9549-b8701811137e-193-1-c000.snappy.parquet</td><td>1218</td><td>1734946216000</td></tr><tr><td>dbfs:/FileStore/data/sales_parquet_2/part-00000-tid-6589554690584742466-751593de-6e17-44bf-b88d-1a91277f76a6-80-1-c000.snappy.parquet</td><td>part-00000-tid-6589554690584742466-751593de-6e17-44bf-b88d-1a91277f76a6-80-1-c000.snappy.parquet</td><td>1218</td><td>1734946013000</td></tr><tr><td>dbfs:/FileStore/data/sales_parquet_2/part-00000-tid-822393280317452396-c3b667af-027e-496e-bdca-42f60f791629-25-1-c000.snappy.parquet</td><td>part-00000-tid-822393280317452396-c3b667af-027e-496e-bdca-42f60f791629-25-1-c000.snappy.parquet</td><td>1255</td><td>1734945510000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/FileStore/data/sales_parquet_2/_SUCCESS",
         "_SUCCESS",
         0,
         1734946217000
        ],
        [
         "dbfs:/FileStore/data/sales_parquet_2/_committed_4376580291416143822",
         "_committed_4376580291416143822",
         124,
         1734946217000
        ],
        [
         "dbfs:/FileStore/data/sales_parquet_2/_committed_6589554690584742466",
         "_committed_6589554690584742466",
         123,
         1734946013000
        ],
        [
         "dbfs:/FileStore/data/sales_parquet_2/_committed_822393280317452396",
         "_committed_822393280317452396",
         122,
         1734945510000
        ],
        [
         "dbfs:/FileStore/data/sales_parquet_2/_delta_log/",
         "_delta_log/",
         0,
         0
        ],
        [
         "dbfs:/FileStore/data/sales_parquet_2/_started_4376580291416143822",
         "_started_4376580291416143822",
         0,
         1734946216000
        ],
        [
         "dbfs:/FileStore/data/sales_parquet_2/_started_6589554690584742466",
         "_started_6589554690584742466",
         0,
         1734946012000
        ],
        [
         "dbfs:/FileStore/data/sales_parquet_2/_started_822393280317452396",
         "_started_822393280317452396",
         0,
         1734945507000
        ],
        [
         "dbfs:/FileStore/data/sales_parquet_2/part-00000-tid-4376580291416143822-0a9fa6c7-7345-4370-9549-b8701811137e-193-1-c000.snappy.parquet",
         "part-00000-tid-4376580291416143822-0a9fa6c7-7345-4370-9549-b8701811137e-193-1-c000.snappy.parquet",
         1218,
         1734946216000
        ],
        [
         "dbfs:/FileStore/data/sales_parquet_2/part-00000-tid-6589554690584742466-751593de-6e17-44bf-b88d-1a91277f76a6-80-1-c000.snappy.parquet",
         "part-00000-tid-6589554690584742466-751593de-6e17-44bf-b88d-1a91277f76a6-80-1-c000.snappy.parquet",
         1218,
         1734946013000
        ],
        [
         "dbfs:/FileStore/data/sales_parquet_2/part-00000-tid-822393280317452396-c3b667af-027e-496e-bdca-42f60f791629-25-1-c000.snappy.parquet",
         "part-00000-tid-822393280317452396-c3b667af-027e-496e-bdca-42f60f791629-25-1-c000.snappy.parquet",
         1255,
         1734945510000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dbutils.fs.ls(\"/FileStore/data/sales_parquet_2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc3ad347-2be2-45a6-8f56-3c8bcd9469a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>col_name</th><th>data_type</th><th>comment</th></tr></thead><tbody><tr><td>empno</td><td>string</td><td>null</td></tr><tr><td>empname</td><td>string</td><td>null</td></tr><tr><td>city</td><td>string</td><td>null</td></tr><tr><td>salary</td><td>int</td><td>null</td></tr><tr><td></td><td></td><td></td></tr><tr><td># Delta Statistics Columns</td><td></td><td></td></tr><tr><td>Column Names</td><td>empname, city, salary, empno</td><td></td></tr><tr><td>Column Selection Method</td><td>first-32</td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td># Detailed Table Information</td><td></td><td></td></tr><tr><td>Catalog</td><td>spark_catalog</td><td></td></tr><tr><td>Database</td><td>default</td><td></td></tr><tr><td>Table</td><td>sales_parquet_2</td><td></td></tr><tr><td>Created Time</td><td>Mon Dec 23 09:18:30 UTC 2024</td><td></td></tr><tr><td>Last Access</td><td>UNKNOWN</td><td></td></tr><tr><td>Created By</td><td>Spark 3.5.0</td><td></td></tr><tr><td>Type</td><td>EXTERNAL</td><td></td></tr><tr><td>Location</td><td>dbfs:/FileStore/data/sales_parquet_2</td><td></td></tr><tr><td>Provider</td><td>delta</td><td></td></tr><tr><td>Owner</td><td>root</td><td></td></tr><tr><td>Table Properties</td><td>[delta.minReaderVersion=1,delta.minWriterVersion=2]</td><td></td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "empno",
         "string",
         null
        ],
        [
         "empname",
         "string",
         null
        ],
        [
         "city",
         "string",
         null
        ],
        [
         "salary",
         "int",
         null
        ],
        [
         "",
         "",
         ""
        ],
        [
         "# Delta Statistics Columns",
         "",
         ""
        ],
        [
         "Column Names",
         "empname, city, salary, empno",
         ""
        ],
        [
         "Column Selection Method",
         "first-32",
         ""
        ],
        [
         "",
         "",
         ""
        ],
        [
         "# Detailed Table Information",
         "",
         ""
        ],
        [
         "Catalog",
         "spark_catalog",
         ""
        ],
        [
         "Database",
         "default",
         ""
        ],
        [
         "Table",
         "sales_parquet_2",
         ""
        ],
        [
         "Created Time",
         "Mon Dec 23 09:18:30 UTC 2024",
         ""
        ],
        [
         "Last Access",
         "UNKNOWN",
         ""
        ],
        [
         "Created By",
         "Spark 3.5.0",
         ""
        ],
        [
         "Type",
         "EXTERNAL",
         ""
        ],
        [
         "Location",
         "dbfs:/FileStore/data/sales_parquet_2",
         ""
        ],
        [
         "Provider",
         "delta",
         ""
        ],
        [
         "Owner",
         "root",
         ""
        ],
        [
         "Table Properties",
         "[delta.minReaderVersion=1,delta.minWriterVersion=2]",
         ""
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 68
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{\"comment\":\"name of the column\"}",
         "name": "col_name",
         "type": "\"string\""
        },
        {
         "metadata": "{\"comment\":\"data type of the column\"}",
         "name": "data_type",
         "type": "\"string\""
        },
        {
         "metadata": "{\"comment\":\"comment of the column\"}",
         "name": "comment",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "describe extended sales_parquet_2\n",
    "-- convert to delta sales_parquet_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "594a5187-6f95-4000-af1b-b3141b2ba20f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>version</th><th>timestamp</th><th>userId</th><th>userName</th><th>operation</th><th>operationParameters</th><th>job</th><th>notebook</th><th>clusterId</th><th>readVersion</th><th>isolationLevel</th><th>isBlindAppend</th><th>operationMetrics</th><th>userMetadata</th><th>engineInfo</th></tr></thead><tbody><tr><td>6</td><td>2024-12-23T10:00:34Z</td><td>141785285425900</td><td>qbex.azure@gmail.com</td><td>RESTORE</td><td>Map(version -> 1, timestamp -> null)</td><td>null</td><td>List(4005581910905466)</td><td>1223-070356-nnvl4fpv</td><td>5</td><td>Serializable</td><td>false</td><td>Map(numRestoredFiles -> 1, removedFilesSize -> 3963, numRemovedFiles -> 3, restoredFilesSize -> 1255, numOfFilesAfterRestore -> 1, tableSizeAfterRestore -> 1255)</td><td>null</td><td>Databricks-Runtime/15.4.x-scala2.12</td></tr><tr><td>5</td><td>2024-12-23T09:47:25Z</td><td>141785285425900</td><td>qbex.azure@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, statsOnLoad -> false, partitionBy -> [])</td><td>null</td><td>List(4005581910905466)</td><td>1223-070356-nnvl4fpv</td><td>4</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 1, numOutputBytes -> 1466)</td><td>null</td><td>Databricks-Runtime/15.4.x-scala2.12</td></tr><tr><td>4</td><td>2024-12-23T09:30:47Z</td><td>141785285425900</td><td>qbex.azure@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, statsOnLoad -> false, partitionBy -> [])</td><td>null</td><td>List(4005581910905466)</td><td>1223-070356-nnvl4fpv</td><td>3</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 1, numOutputBytes -> 1242)</td><td>null</td><td>Databricks-Runtime/15.4.x-scala2.12</td></tr><tr><td>3</td><td>2024-12-23T09:29:14Z</td><td>141785285425900</td><td>qbex.azure@gmail.com</td><td>UPDATE</td><td>Map(predicate -> [\"(empno#3836 = E1)\"])</td><td>null</td><td>List(4005581910905466)</td><td>1223-070356-nnvl4fpv</td><td>2</td><td>WriteSerializable</td><td>false</td><td>Map(numRemovedFiles -> 1, numRemovedBytes -> 1255, numCopiedRows -> 2, numDeletionVectorsAdded -> 0, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 1713, numDeletionVectorsUpdated -> 0, scanTimeMs -> 718, numAddedFiles -> 1, numUpdatedRows -> 1, numAddedBytes -> 1255, rewriteTimeMs -> 995)</td><td>null</td><td>Databricks-Runtime/15.4.x-scala2.12</td></tr><tr><td>2</td><td>2024-12-23T09:28:14Z</td><td>141785285425900</td><td>qbex.azure@gmail.com</td><td>UPDATE</td><td>Map(predicate -> [\"(empno#2854 = E1)\"])</td><td>null</td><td>List(4005581910905466)</td><td>1223-070356-nnvl4fpv</td><td>1</td><td>WriteSerializable</td><td>false</td><td>Map(numRemovedFiles -> 1, numRemovedBytes -> 1255, numCopiedRows -> 2, numDeletionVectorsAdded -> 0, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 2189, numDeletionVectorsUpdated -> 0, scanTimeMs -> 1357, numAddedFiles -> 1, numUpdatedRows -> 1, numAddedBytes -> 1255, rewriteTimeMs -> 832)</td><td>null</td><td>Databricks-Runtime/15.4.x-scala2.12</td></tr><tr><td>1</td><td>2024-12-23T09:28:02Z</td><td>141785285425900</td><td>qbex.azure@gmail.com</td><td>UPDATE</td><td>Map(predicate -> [\"(empno#2283 = E1)\"])</td><td>null</td><td>List(4005581910905466)</td><td>1223-070356-nnvl4fpv</td><td>0</td><td>WriteSerializable</td><td>false</td><td>Map(numRemovedFiles -> 1, numRemovedBytes -> 1255, numCopiedRows -> 2, numDeletionVectorsAdded -> 0, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 3129, numDeletionVectorsUpdated -> 0, scanTimeMs -> 1751, numAddedFiles -> 1, numUpdatedRows -> 1, numAddedBytes -> 1255, rewriteTimeMs -> 1364)</td><td>null</td><td>Databricks-Runtime/15.4.x-scala2.12</td></tr><tr><td>0</td><td>2024-12-23T09:21:34Z</td><td>141785285425900</td><td>qbex.azure@gmail.com</td><td>CREATE OR REPLACE TABLE AS SELECT</td><td>Map(partitionBy -> [], clusterBy -> [], description -> null, isManaged -> false, properties -> {}, statsOnLoad -> false)</td><td>null</td><td>List(4005581910905466)</td><td>1223-070356-nnvl4fpv</td><td>null</td><td>WriteSerializable</td><td>false</td><td>Map(numFiles -> 1, numOutputRows -> 3, numOutputBytes -> 1255)</td><td>null</td><td>Databricks-Runtime/15.4.x-scala2.12</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         6,
         "2024-12-23T10:00:34Z",
         "141785285425900",
         "qbex.azure@gmail.com",
         "RESTORE",
         {
          "timestamp": null,
          "version": "1"
         },
         null,
         [
          "4005581910905466"
         ],
         "1223-070356-nnvl4fpv",
         5,
         "Serializable",
         false,
         {
          "numOfFilesAfterRestore": "1",
          "numRemovedFiles": "3",
          "numRestoredFiles": "1",
          "removedFilesSize": "3963",
          "restoredFilesSize": "1255",
          "tableSizeAfterRestore": "1255"
         },
         null,
         "Databricks-Runtime/15.4.x-scala2.12"
        ],
        [
         5,
         "2024-12-23T09:47:25Z",
         "141785285425900",
         "qbex.azure@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]",
          "statsOnLoad": "false"
         },
         null,
         [
          "4005581910905466"
         ],
         "1223-070356-nnvl4fpv",
         4,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "1466",
          "numOutputRows": "1"
         },
         null,
         "Databricks-Runtime/15.4.x-scala2.12"
        ],
        [
         4,
         "2024-12-23T09:30:47Z",
         "141785285425900",
         "qbex.azure@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]",
          "statsOnLoad": "false"
         },
         null,
         [
          "4005581910905466"
         ],
         "1223-070356-nnvl4fpv",
         3,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "1242",
          "numOutputRows": "1"
         },
         null,
         "Databricks-Runtime/15.4.x-scala2.12"
        ],
        [
         3,
         "2024-12-23T09:29:14Z",
         "141785285425900",
         "qbex.azure@gmail.com",
         "UPDATE",
         {
          "predicate": "[\"(empno#3836 = E1)\"]"
         },
         null,
         [
          "4005581910905466"
         ],
         "1223-070356-nnvl4fpv",
         2,
         "WriteSerializable",
         false,
         {
          "executionTimeMs": "1713",
          "numAddedBytes": "1255",
          "numAddedChangeFiles": "0",
          "numAddedFiles": "1",
          "numCopiedRows": "2",
          "numDeletionVectorsAdded": "0",
          "numDeletionVectorsRemoved": "0",
          "numDeletionVectorsUpdated": "0",
          "numRemovedBytes": "1255",
          "numRemovedFiles": "1",
          "numUpdatedRows": "1",
          "rewriteTimeMs": "995",
          "scanTimeMs": "718"
         },
         null,
         "Databricks-Runtime/15.4.x-scala2.12"
        ],
        [
         2,
         "2024-12-23T09:28:14Z",
         "141785285425900",
         "qbex.azure@gmail.com",
         "UPDATE",
         {
          "predicate": "[\"(empno#2854 = E1)\"]"
         },
         null,
         [
          "4005581910905466"
         ],
         "1223-070356-nnvl4fpv",
         1,
         "WriteSerializable",
         false,
         {
          "executionTimeMs": "2189",
          "numAddedBytes": "1255",
          "numAddedChangeFiles": "0",
          "numAddedFiles": "1",
          "numCopiedRows": "2",
          "numDeletionVectorsAdded": "0",
          "numDeletionVectorsRemoved": "0",
          "numDeletionVectorsUpdated": "0",
          "numRemovedBytes": "1255",
          "numRemovedFiles": "1",
          "numUpdatedRows": "1",
          "rewriteTimeMs": "832",
          "scanTimeMs": "1357"
         },
         null,
         "Databricks-Runtime/15.4.x-scala2.12"
        ],
        [
         1,
         "2024-12-23T09:28:02Z",
         "141785285425900",
         "qbex.azure@gmail.com",
         "UPDATE",
         {
          "predicate": "[\"(empno#2283 = E1)\"]"
         },
         null,
         [
          "4005581910905466"
         ],
         "1223-070356-nnvl4fpv",
         0,
         "WriteSerializable",
         false,
         {
          "executionTimeMs": "3129",
          "numAddedBytes": "1255",
          "numAddedChangeFiles": "0",
          "numAddedFiles": "1",
          "numCopiedRows": "2",
          "numDeletionVectorsAdded": "0",
          "numDeletionVectorsRemoved": "0",
          "numDeletionVectorsUpdated": "0",
          "numRemovedBytes": "1255",
          "numRemovedFiles": "1",
          "numUpdatedRows": "1",
          "rewriteTimeMs": "1364",
          "scanTimeMs": "1751"
         },
         null,
         "Databricks-Runtime/15.4.x-scala2.12"
        ],
        [
         0,
         "2024-12-23T09:21:34Z",
         "141785285425900",
         "qbex.azure@gmail.com",
         "CREATE OR REPLACE TABLE AS SELECT",
         {
          "clusterBy": "[]",
          "description": null,
          "isManaged": "false",
          "partitionBy": "[]",
          "properties": "{}",
          "statsOnLoad": "false"
         },
         null,
         [
          "4005581910905466"
         ],
         "1223-070356-nnvl4fpv",
         null,
         "WriteSerializable",
         false,
         {
          "numFiles": "1",
          "numOutputBytes": "1255",
          "numOutputRows": "3"
         },
         null,
         "Databricks-Runtime/15.4.x-scala2.12"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 71
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "version",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "timestamp",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "userId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "userName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operation",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operationParameters",
         "type": "{\"type\":\"map\",\"keyType\":\"string\",\"valueType\":\"string\",\"valueContainsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "job",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"jobId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"jobName\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"jobRunId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"runId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"jobOwnerId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"triggerType\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "notebook",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"notebookId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "clusterId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "readVersion",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "isolationLevel",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "isBlindAppend",
         "type": "\"boolean\""
        },
        {
         "metadata": "{}",
         "name": "operationMetrics",
         "type": "{\"type\":\"map\",\"keyType\":\"string\",\"valueType\":\"string\",\"valueContainsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "userMetadata",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "engineInfo",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%sql\n",
    "-- restore sales_delta_2 to version as of 1\n",
    "-- select * from sales_delta_2\n",
    "describe history sales_delta_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3005bd1-9487-4218-a986-7366fef64f63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vacuum operations in Delta Lake\n",
    "from delta import DeltaTable\n",
    "dt = DeltaTable.forName(spark,\"sales_delta_2\")\n",
    "\n",
    "spark.conf.set(\"spark.databricks.delta.retentionDurationCheck.enabled\",\"false\")\n",
    "dt.vacuum(0)\n",
    "# # Get table properties\n",
    "# properties = dt.detail().collect()\n",
    "\n",
    "# # Display properties\n",
    "# for prop in properties:\n",
    "#     print(prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e80b0ea1-849b-412e-9f4b-f0b99d438009",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "org.apache.spark.SparkException: [FAILED_READ_FILE.DBR_FILE_NOT_EXIST] Error while reading file dbfs:/FileStore/data/sales_delta_2/part-00000-60f5a60d-da17-4821-ab3e-4957102d2ed7-c000.snappy.parquet. [DELTA_FILE_NOT_FOUND_DETAILED] File dbfs:/FileStore/data/sales_delta_2/part-00000-60f5a60d-da17-4821-ab3e-4957102d2ed7-c000.snappy.parquet referenced in the transaction log cannot be found. This occurs when data has been manually deleted from the file system rather than using the table `DELETE` statement. For more information, see https://docs.databricks.com/delta/delta-intro.html#frequently-asked-questions SQLSTATE: KD001\n",
       "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.fileNotExistErrorDBR(QueryExecutionErrors.scala:1069)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1$$anon$2.logMissingFileNameAndThrow(FileScanRDD.scala:780)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1$$anon$2.getNext(FileScanRDD.scala:676)\n",
       "\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.$anonfun$prepareNextFile$1(FileScanRDD.scala:964)\n",
       "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
       "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
       "\tat scala.util.Success.map(Try.scala:213)\n",
       "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
       "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
       "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
       "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
       "\tat org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:157)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)\n",
       "\tat org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:113)\n",
       "\tat com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)\n",
       "\tat org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:112)\n",
       "\tat org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:89)\n",
       "\tat org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:154)\n",
       "\tat org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:157)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
       "\tat java.lang.Thread.run(Thread.java:750)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$runJob$1(DAGScheduler.scala:1412)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1400)\n",
       "\tat org.apache.spark.SparkContext.runJobInternal(SparkContext.scala:3157)\n",
       "\tat org.apache.spark.sql.execution.collect.Collector.$anonfun$runSparkJobs$1(Collector.scala:355)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.execution.collect.Collector.runSparkJobs(Collector.scala:299)\n",
       "\tat org.apache.spark.sql.execution.collect.Collector.$anonfun$collect$1(Collector.scala:384)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.execution.collect.Collector.collect(Collector.scala:381)\n",
       "\tat org.apache.spark.sql.execution.collect.Collector$.collect(Collector.scala:122)\n",
       "\tat org.apache.spark.sql.execution.collect.Collector$.collect(Collector.scala:131)\n",
       "\tat org.apache.spark.sql.execution.qrc.InternalRowFormat$.collect(cachedSparkResults.scala:94)\n",
       "\tat org.apache.spark.sql.execution.qrc.InternalRowFormat$.collect(cachedSparkResults.scala:90)\n",
       "\tat org.apache.spark.sql.execution.qrc.InternalRowFormat$.collect(cachedSparkResults.scala:78)\n",
       "\tat org.apache.spark.sql.execution.qrc.ResultCacheManager.$anonfun$computeResult$1(ResultCacheManager.scala:552)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.execution.qrc.ResultCacheManager.collectResult$1(ResultCacheManager.scala:546)\n",
       "\tat org.apache.spark.sql.execution.qrc.ResultCacheManager.computeResult(ResultCacheManager.scala:563)\n",
       "\tat org.apache.spark.sql.execution.qrc.ResultCacheManager.$anonfun$getOrComputeResultInternal$1(ResultCacheManager.scala:401)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat org.apache.spark.sql.execution.qrc.ResultCacheManager.getOrComputeResultInternal(ResultCacheManager.scala:400)\n",
       "\tat org.apache.spark.sql.execution.qrc.ResultCacheManager.getOrComputeResult(ResultCacheManager.scala:319)\n",
       "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeCollectResult$1(SparkPlan.scala:572)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.execution.SparkPlan.executeCollectResult(SparkPlan.scala:569)\n",
       "\tat org.apache.spark.sql.Dataset.collectResult(Dataset.scala:3844)\n",
       "\tat org.apache.spark.sql.Dataset.$anonfun$collectResult$1(Dataset.scala:3835)\n",
       "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$3(Dataset.scala:4807)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1179)\n",
       "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4805)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$10(SQLExecution.scala:462)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:800)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:334)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1180)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:205)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:737)\n",
       "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4805)\n",
       "\tat org.apache.spark.sql.Dataset.collectResult(Dataset.scala:3834)\n",
       "\tat com.databricks.backend.daemon.driver.OutputAggregator$.withOutputAggregation0(OutputAggregator.scala:325)\n",
       "\tat com.databricks.backend.daemon.driver.OutputAggregator$.withOutputAggregation(OutputAggregator.scala:101)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.executeSql(DriverLocal.scala:441)\n",
       "\tat com.databricks.backend.daemon.driver.JupyterDriverLocal.repl(JupyterDriverLocal.scala:1054)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$33(DriverLocal.scala:1172)\n",
       "\tat com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:133)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$28(DriverLocal.scala:1163)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:96)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:96)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$1(DriverLocal.scala:1099)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal$.$anonfun$maybeSynchronizeExecution$4(DriverLocal.scala:1519)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:776)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$2(DriverWrapper.scala:932)\n",
       "\tat scala.util.Try$.apply(Try.scala:213)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:921)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:953)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:717)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:785)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:586)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:512)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:306)\n",
       "\tat java.lang.Thread.run(Thread.java:750)\n",
       "Caused by: java.io.FileNotFoundException: /FileStore/data/sales_delta_2/part-00000-60f5a60d-da17-4821-ab3e-4957102d2ed7-c000.snappy.parquet\n",
       "\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:122)\n",
       "\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:70)\n",
       "\tat com.databricks.backend.daemon.data.client.DatabricksFileSystemV1.open(DatabricksFileSystemV1.scala:80)\n",
       "\tat com.databricks.backend.daemon.data.client.DatabricksFileSystemV1.open(DatabricksFileSystemV1.scala:89)\n",
       "\tat com.databricks.backend.daemon.data.client.DatabricksFileSystem.open(DatabricksFileSystem.scala:91)\n",
       "\tat com.databricks.backend.daemon.data.client.DbfsHadoop3.$anonfun$openFileWithOptions$6(DbfsHadoop3.scala:79)\n",
       "\tat org.apache.hadoop.util.LambdaUtils.eval(LambdaUtils.java:52)\n",
       "\tat com.databricks.backend.daemon.data.client.DbfsHadoop3.openFileWithOptions(DbfsHadoop3.scala:79)\n",
       "\tat org.apache.hadoop.fs.FileSystem$FSDataInputStreamBuilder.build(FileSystem.java:4913)\n",
       "\tat com.databricks.common.filesystem.LokiFileSystem.openFileWithOptions(LokiFileSystem.scala:335)\n",
       "\tat org.apache.hadoop.fs.FileSystem$FSDataInputStreamBuilder.build(FileSystem.java:4913)\n",
       "\tat com.databricks.spark.util.DatabricksRangeFetcher.fetchRange(DatabricksRangeFetcher.scala:73)\n",
       "\tat com.databricks.io.RangeFetcher$.fetch(RangeFetcher.scala:104)\n",
       "\tat com.databricks.io.RangeFetcher.fetch(RangeFetcher.scala)\n",
       "\tat com.databricks.sql.io.HDFSStorage$ReadFileImpl.lambda$fetchRange$0(HDFSStorage.java:104)\n",
       "\tat com.databricks.sql.io.Futures.run(Futures.java:74)\n",
       "\tat com.databricks.sql.io.PendingFutures.submit(PendingFutures.java:63)\n",
       "\tat com.databricks.sql.io.Storage$ReadFile.submit(Storage.java:189)\n",
       "\tat com.databricks.sql.io.HDFSStorage$ReadFileImpl.fetchRange(HDFSStorage.java:101)\n",
       "\tat com.databricks.sql.io.Storage.fetchRange(Storage.java:210)\n",
       "\tat com.databricks.sql.io.parquet.CachingParquetFileReader$FooterByteReader.readTail(CachingParquetFileReader.java:338)\n",
       "\tat com.databricks.sql.io.parquet.CachingParquetFileReader$FooterByteReader.read(CachingParquetFileReader.java:358)\n",
       "\tat com.databricks.sql.io.parquet.CachingParquetFooterReader.lambda$readFooterFromStorage$2(CachingParquetFooterReader.java:220)\n",
       "\tat org.apache.spark.util.JavaFrameProfiler.record(JavaFrameProfiler.java:18)\n",
       "\tat com.databricks.sql.io.parquet.CachingParquetFooterReader.readFooterFromStorage(CachingParquetFooterReader.java:214)\n",
       "\tat com.databricks.sql.io.parquet.CachingParquetFooterReader.readFooter(CachingParquetFooterReader.java:134)\n",
       "\tat com.databricks.sql.io.parquet.CachingParquetFileReader.readFooter(CachingParquetFileReader.java:387)\n",
       "\tat org.apache.spark.sql.execution.datasources.parquet.SpecificParquetRecordReaderBase.prepare(SpecificParquetRecordReaderBase.java:162)\n",
       "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anon$1.apply(ParquetFileFormat.scala:415)\n",
       "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anon$1.apply(ParquetFileFormat.scala:258)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1$$anon$2.getNext(FileScanRDD.scala:639)\n",
       "\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.$anonfun$prepareNextFile$1(FileScanRDD.scala:964)\n",
       "\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n",
       "\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n",
       "\tat scala.util.Success.map(Try.scala:213)\n",
       "\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n",
       "\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n",
       "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
       "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
       "\tat org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:157)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)\n",
       "\tat org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:113)\n",
       "\tat com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)\n",
       "\tat org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:112)\n",
       "\tat org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:89)\n",
       "\tat org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:154)\n",
       "\tat org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:157)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
       "\t... 1 more\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "[FAILED_READ_FILE.DBR_FILE_NOT_EXIST] Error while reading file dbfs:/FileStore/data/sales_delta_2/part-00000-60f5a60d-da17-4821-ab3e-4957102d2ed7-c000.snappy.parquet. [DELTA_FILE_NOT_FOUND_DETAILED] File dbfs:/FileStore/data/sales_delta_2/part-00000-60f5a60d-da17-4821-ab3e-4957102d2ed7-c000.snappy.parquet referenced in the transaction log cannot be found. This occurs when data has been manually deleted from the file system rather than using the table `DELETE` statement. For more information, see https://docs.databricks.com/delta/delta-intro.html#frequently-asked-questions SQLSTATE: KD001"
       },
       "removedWidgets": [],
       "sqlProps": {
        "errorClass": "FAILED_READ_FILE.DBR_FILE_NOT_EXIST",
        "pysparkCallSite": null,
        "pysparkFragment": null,
        "sqlState": "KD001",
        "stackTrace": null,
        "startIndex": null,
        "stopIndex": null
       },
       "stackFrames": [
        "org.apache.spark.SparkException: [FAILED_READ_FILE.DBR_FILE_NOT_EXIST] Error while reading file dbfs:/FileStore/data/sales_delta_2/part-00000-60f5a60d-da17-4821-ab3e-4957102d2ed7-c000.snappy.parquet. [DELTA_FILE_NOT_FOUND_DETAILED] File dbfs:/FileStore/data/sales_delta_2/part-00000-60f5a60d-da17-4821-ab3e-4957102d2ed7-c000.snappy.parquet referenced in the transaction log cannot be found. This occurs when data has been manually deleted from the file system rather than using the table `DELETE` statement. For more information, see https://docs.databricks.com/delta/delta-intro.html#frequently-asked-questions SQLSTATE: KD001\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.fileNotExistErrorDBR(QueryExecutionErrors.scala:1069)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1$$anon$2.logMissingFileNameAndThrow(FileScanRDD.scala:780)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1$$anon$2.getNext(FileScanRDD.scala:676)\n\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.$anonfun$prepareNextFile$1(FileScanRDD.scala:964)\n\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n\tat scala.util.Success.map(Try.scala:213)\n\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n\tat org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:157)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)\n\tat org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:113)\n\tat com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)\n\tat org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:112)\n\tat org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:89)\n\tat org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:154)\n\tat org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:157)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$runJob$1(DAGScheduler.scala:1412)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1400)\n\tat org.apache.spark.SparkContext.runJobInternal(SparkContext.scala:3157)\n\tat org.apache.spark.sql.execution.collect.Collector.$anonfun$runSparkJobs$1(Collector.scala:355)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.execution.collect.Collector.runSparkJobs(Collector.scala:299)\n\tat org.apache.spark.sql.execution.collect.Collector.$anonfun$collect$1(Collector.scala:384)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.execution.collect.Collector.collect(Collector.scala:381)\n\tat org.apache.spark.sql.execution.collect.Collector$.collect(Collector.scala:122)\n\tat org.apache.spark.sql.execution.collect.Collector$.collect(Collector.scala:131)\n\tat org.apache.spark.sql.execution.qrc.InternalRowFormat$.collect(cachedSparkResults.scala:94)\n\tat org.apache.spark.sql.execution.qrc.InternalRowFormat$.collect(cachedSparkResults.scala:90)\n\tat org.apache.spark.sql.execution.qrc.InternalRowFormat$.collect(cachedSparkResults.scala:78)\n\tat org.apache.spark.sql.execution.qrc.ResultCacheManager.$anonfun$computeResult$1(ResultCacheManager.scala:552)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.execution.qrc.ResultCacheManager.collectResult$1(ResultCacheManager.scala:546)\n\tat org.apache.spark.sql.execution.qrc.ResultCacheManager.computeResult(ResultCacheManager.scala:563)\n\tat org.apache.spark.sql.execution.qrc.ResultCacheManager.$anonfun$getOrComputeResultInternal$1(ResultCacheManager.scala:401)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.execution.qrc.ResultCacheManager.getOrComputeResultInternal(ResultCacheManager.scala:400)\n\tat org.apache.spark.sql.execution.qrc.ResultCacheManager.getOrComputeResult(ResultCacheManager.scala:319)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeCollectResult$1(SparkPlan.scala:572)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollectResult(SparkPlan.scala:569)\n\tat org.apache.spark.sql.Dataset.collectResult(Dataset.scala:3844)\n\tat org.apache.spark.sql.Dataset.$anonfun$collectResult$1(Dataset.scala:3835)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$3(Dataset.scala:4807)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1179)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4805)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$10(SQLExecution.scala:462)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:800)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:334)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1180)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:205)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:737)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4805)\n\tat org.apache.spark.sql.Dataset.collectResult(Dataset.scala:3834)\n\tat com.databricks.backend.daemon.driver.OutputAggregator$.withOutputAggregation0(OutputAggregator.scala:325)\n\tat com.databricks.backend.daemon.driver.OutputAggregator$.withOutputAggregation(OutputAggregator.scala:101)\n\tat com.databricks.backend.daemon.driver.DriverLocal.executeSql(DriverLocal.scala:441)\n\tat com.databricks.backend.daemon.driver.JupyterDriverLocal.repl(JupyterDriverLocal.scala:1054)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$33(DriverLocal.scala:1172)\n\tat com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:133)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$28(DriverLocal.scala:1163)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:96)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:96)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$1(DriverLocal.scala:1099)\n\tat com.databricks.backend.daemon.driver.DriverLocal$.$anonfun$maybeSynchronizeExecution$4(DriverLocal.scala:1519)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:776)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$2(DriverWrapper.scala:932)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:921)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:953)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:717)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:785)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:586)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:512)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:306)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.io.FileNotFoundException: /FileStore/data/sales_delta_2/part-00000-60f5a60d-da17-4821-ab3e-4957102d2ed7-c000.snappy.parquet\n\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:122)\n\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:70)\n\tat com.databricks.backend.daemon.data.client.DatabricksFileSystemV1.open(DatabricksFileSystemV1.scala:80)\n\tat com.databricks.backend.daemon.data.client.DatabricksFileSystemV1.open(DatabricksFileSystemV1.scala:89)\n\tat com.databricks.backend.daemon.data.client.DatabricksFileSystem.open(DatabricksFileSystem.scala:91)\n\tat com.databricks.backend.daemon.data.client.DbfsHadoop3.$anonfun$openFileWithOptions$6(DbfsHadoop3.scala:79)\n\tat org.apache.hadoop.util.LambdaUtils.eval(LambdaUtils.java:52)\n\tat com.databricks.backend.daemon.data.client.DbfsHadoop3.openFileWithOptions(DbfsHadoop3.scala:79)\n\tat org.apache.hadoop.fs.FileSystem$FSDataInputStreamBuilder.build(FileSystem.java:4913)\n\tat com.databricks.common.filesystem.LokiFileSystem.openFileWithOptions(LokiFileSystem.scala:335)\n\tat org.apache.hadoop.fs.FileSystem$FSDataInputStreamBuilder.build(FileSystem.java:4913)\n\tat com.databricks.spark.util.DatabricksRangeFetcher.fetchRange(DatabricksRangeFetcher.scala:73)\n\tat com.databricks.io.RangeFetcher$.fetch(RangeFetcher.scala:104)\n\tat com.databricks.io.RangeFetcher.fetch(RangeFetcher.scala)\n\tat com.databricks.sql.io.HDFSStorage$ReadFileImpl.lambda$fetchRange$0(HDFSStorage.java:104)\n\tat com.databricks.sql.io.Futures.run(Futures.java:74)\n\tat com.databricks.sql.io.PendingFutures.submit(PendingFutures.java:63)\n\tat com.databricks.sql.io.Storage$ReadFile.submit(Storage.java:189)\n\tat com.databricks.sql.io.HDFSStorage$ReadFileImpl.fetchRange(HDFSStorage.java:101)\n\tat com.databricks.sql.io.Storage.fetchRange(Storage.java:210)\n\tat com.databricks.sql.io.parquet.CachingParquetFileReader$FooterByteReader.readTail(CachingParquetFileReader.java:338)\n\tat com.databricks.sql.io.parquet.CachingParquetFileReader$FooterByteReader.read(CachingParquetFileReader.java:358)\n\tat com.databricks.sql.io.parquet.CachingParquetFooterReader.lambda$readFooterFromStorage$2(CachingParquetFooterReader.java:220)\n\tat org.apache.spark.util.JavaFrameProfiler.record(JavaFrameProfiler.java:18)\n\tat com.databricks.sql.io.parquet.CachingParquetFooterReader.readFooterFromStorage(CachingParquetFooterReader.java:214)\n\tat com.databricks.sql.io.parquet.CachingParquetFooterReader.readFooter(CachingParquetFooterReader.java:134)\n\tat com.databricks.sql.io.parquet.CachingParquetFileReader.readFooter(CachingParquetFileReader.java:387)\n\tat org.apache.spark.sql.execution.datasources.parquet.SpecificParquetRecordReaderBase.prepare(SpecificParquetRecordReaderBase.java:162)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anon$1.apply(ParquetFileFormat.scala:415)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anon$1.apply(ParquetFileFormat.scala:258)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1$$anon$2.getNext(FileScanRDD.scala:639)\n\tat org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.$anonfun$prepareNextFile$1(FileScanRDD.scala:964)\n\tat scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)\n\tat scala.util.Success.$anonfun$map$1(Try.scala:255)\n\tat scala.util.Success.map(Try.scala:213)\n\tat scala.concurrent.Future.$anonfun$map$1(Future.scala:292)\n\tat scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)\n\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n\tat org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:157)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)\n\tat org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:113)\n\tat com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)\n\tat org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:112)\n\tat org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:89)\n\tat org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:154)\n\tat org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:157)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select * from sales_delta_2@v0"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 989203859431572,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Delta Lake Part - 1 (sol)",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
